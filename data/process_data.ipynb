{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os, os.path\n",
    "# from sklearn.model_selection import train_test_split \n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Process Image Labels Data to Numpy Array\n",
    "- Total number of images for the trainning dataset: 414,796\n",
    "    - will split the training into training and validation datasets\n",
    "- Total number of images in the validation dataset: 5,495\n",
    "    - will use the validation dataset for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_filename(path) :\n",
    "    \n",
    "    sorted_filename = np.sort(os.listdir(path))\n",
    "    return sorted_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def filename_label_reg(sorted_filename, label_path, name) :\n",
    "    labels_sorted = np.load(label_path)\n",
    "    labels_sorted = np.transpose(labels_sorted)\n",
    "\n",
    "    final = pd.DataFrame(data={\n",
    "        \"Image file\" : sorted_filename,\n",
    "        \"Arousal\" : labels_sorted[0],\n",
    "        \"Valence\" : labels_sorted[1]\n",
    "    })\n",
    "\n",
    "    final.to_csv(name, index=False, header=False)\n",
    "\n",
    "def filename_label_class(sorted_filename, label_path, name) :\n",
    "    labels_sorted = np.load(label_path)\n",
    "\n",
    "    final = pd.DataFrame(data={\n",
    "        \"Image file\" : sorted_filename,\n",
    "        \"Arousal\" : labels_sorted\n",
    "    })\n",
    "\n",
    "    final.to_csv(name, index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main() :\n",
    "    \n",
    "    # training images\n",
    "    train_filename = load_filename(\"train_set\\\\New folder\\\\images\")\n",
    "    train_class = \"trainval_class.npy\"\n",
    "    train_reg = \"trainval_reg.npy\"\n",
    "\n",
    "    filename_label_class(train_filename, train_class, \"trainval_name_classlable.csv\")\n",
    "    filename_label_reg(train_filename, train_reg, \"trainval_name_reglabel.csv\")\n",
    "\n",
    "\n",
    "    # validation images\n",
    "    test_filename = load_filename(\"val_set\\\\New folder\\\\images\")\n",
    "    test_class = \"test_class_sorted.npy\"\n",
    "    test_reg = \"test_reg_sorted.npy\"\n",
    "\n",
    "    filename_label_class(test_filename, test_class, \"test_name_classlable.csv\")\n",
    "    filename_label_reg(test_filename, test_reg, \"test_name_reglabel.csv\")\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_path(sorted_filename, path_dest_name) :\n",
    "    all_img_path = []\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for image in sorted_filename :\n",
    "        count += 1\n",
    "        all_img_path.append(image.split('.')[0])\n",
    "        if (count % 10000 == 0) : print(\"processed\", count, \"images\")\n",
    "\n",
    "    all_img_path = np.asarray(all_img_path)\n",
    "    np.save(path_dest_name, all_img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Process Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_label(path, file_num_arr, label_dest_name) :\n",
    "    \n",
    "    labels = []\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for file_num in file_num_arr :\n",
    "        gc.collect()\n",
    "        emotion = (np.load(path + \"/\" + file_num + \"_exp.npy\"))\n",
    "        valence = (np.load(path + \"/\" + file_num + \"_val.npy\"))\n",
    "        arousal = (np.load(path + \"/\" + file_num + \"_aro.npy\"))\n",
    "        labels.append([emotion, valence, arousal])\n",
    "        count += 1\n",
    "        if (count % 5000 == 0) : print(\"processed\", count, \"labels\")\n",
    "\n",
    "    labels = np.asarray(labels)\n",
    "    np.save(label_dest_name, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_img_cnt(paths) :\n",
    "    total_img_cnt = 0\n",
    "    for path in paths :\n",
    "        total_img_cnt += len([file for file in os.listdir(path)])\n",
    "    \n",
    "    return total_img_cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load image path and labels\n",
    "- Each image is numbered non-consecutively\n",
    "- The path contain the image's number only\n",
    "- with the same order, load into np array the labels of each image as a 2d array: (total number of images, 3)\n",
    "    - img_label_arr = [emotion, valence, arousal]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process path and labels of images in the train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_train_set() :\n",
    "    # path to the train_set folders\n",
    "    train_img_path = \"C:/Phanh/train_set/train_set/images\"\n",
    "    train_annotation_path = \"C:/Phanh/train_set/train_set/annotations\"\n",
    "\n",
    "    # load the name of all image files (images are numbered not consecutively)\n",
    "    sorted_train_file = load_filename(train_img_path)\n",
    "    path_filename = \"C:/Phanh/BuAnhNet/EAAI23/train_set_path.npy\"\n",
    "\n",
    "    # load and save image data into numpy array and the image numbers\n",
    "    process_path(sorted_train_file, path_filename)\n",
    "    train_file_num = np.load(path_filename)\n",
    "\n",
    "    # load and save labels into numpy array\n",
    "    label_filename = \"C:/Phanh/BuAnhNet/EAAI23/train_set_label.npy\"\n",
    "    process_label(train_annotation_path, train_file_num, label_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process path and labels of images in the val_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_val_set() :\n",
    "    # path to the train_set folders\n",
    "    val_img_path = \"C:/Phanh/val_set/images\"\n",
    "    val_annotation_path = \"C:/Phanh/val_set/annotations\"\n",
    "\n",
    "    # load the name of all image files (images are numbered not consecutively)\n",
    "    sorted_val_file = load_filename(val_img_path)\n",
    "    path_filename = \"C:/Phanh/BuAnhNet/EAAI23/val_set_path.npy\"\n",
    "\n",
    "    # load and save image data into numpy array and the image numbers\n",
    "    process_path(sorted_val_file, path_filename)\n",
    "    val_file_num = np.load(path_filename)\n",
    "\n",
    "    # load and save labels into numpy array\n",
    "    label_filename = \"C:/Phanh/BuAnhNet/EAAI23/val_set_label.npy\"\n",
    "    process_label(val_annotation_path, val_file_num, label_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train, y_train = path_arr, label_arr\n",
    "def train_val_split(path_arr, label_arr, train_ratio=0.8, shuffle=True, seed=1) :\n",
    "    # x_train, x_val, y_train, y_val\n",
    "    train_path, val_path, train_label, val_label = train_test_split(path_arr, label_arr, test_size=float(1-train_ratio), random_state=seed, shuffle=shuffle)\n",
    "\n",
    "    np.save(\"train_path.npy\", train_path)\n",
    "    np.save(\"val_path.npy\", val_path)\n",
    "    np.save(\"train_label.npy\", train_label)\n",
    "    np.save(\"val_label.npy\", val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main() :\n",
    "    path_arr = np.load(\"train_set_path.npy\")\n",
    "    label_arr = np.load(\"train_set_label.npy\")\n",
    "\n",
    "    train_val_split(path_arr, label_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def separate(path, class_filename, reg_filename) :\n",
    "    # separate classification data from regression data\n",
    "    org_arr = np.load(path)\n",
    "    transposed = np.transpose(org_arr)\n",
    "\n",
    "    classification = transposed[0]\n",
    "    regression = np.asarray([transposed[1], transposed[2]]) # valence, arousal\n",
    "    regression_transposed = np.transpose(regression)\n",
    "\n",
    "    np.save(class_filename, classification)\n",
    "    np.save(reg_filename, regression_transposed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = \"C:/Phanh/BuAnhNet/EAAI23/archive/test_set_label.npy\"\n",
    "\n",
    "separate(test_set, \"test_class_sorted.npy\", \"test_reg_sorted.npy\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e28bfe5e849496f1d027a6bcc8730a360d479bceb67f0622f77bd617aebb68f4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
